{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common import policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import EnvironmentConfigurations as EnvConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_freq = 25000\n",
    "\n",
    "class AgentCallback(BaseCallback):\n",
    "  def __init__(self, check_freq, save_path, verbose=1):\n",
    "    super(AgentCallback, self).__init__(verbose)\n",
    "    self.check_freq = check_freq\n",
    "    self.save_path = save_path\n",
    "\n",
    "  def __init_callback(self):\n",
    "    if self.save_path is not None:\n",
    "      os.makedirs(self.save_path, exist_ok=True)\n",
    "  \n",
    "  def _on_step(self):\n",
    "    if self.n_calls % self.check_freq == 0:\n",
    "      model_path = os.path.join(self.save_path, f\"model_{self.n_calls}\")\n",
    "      self.model.save(model_path)\n",
    "    return True\n",
    "  \n",
    "  \n",
    "agentCallback = AgentCallback(check_freq=evaluation_freq, save_path=f\"{EnvConfig.AGENT_MODEL_PATH_PREFIX}{EnvConfig.configurations[EnvConfig.CURRENT_CONFIGURATION_INDEX]['name']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Cnn import CustomCNN\n",
    "from EnvironmentHelpers import create_vectorised_environment\n",
    "from utils.layer_activation_monitoring import LayerActivationMonitoring, register_hooks\n",
    "from utils.layer_activation_monitoring import plot_activations\n",
    "\n",
    "env_params = {\n",
    "    \"env_config\": EnvConfig.configurations[EnvConfig.CURRENT_CONFIGURATION_INDEX],\n",
    "    \"is_reward_shaping_on\": True,\n",
    "    \"render\": False\n",
    "}\n",
    "\n",
    "evaluation_env_params = {\n",
    "    \"env_config\": EnvConfig.configurations[EnvConfig.CURRENT_CONFIGURATION_INDEX],\n",
    "    \"is_reward_shaping_on\": False,\n",
    "    \"render\": False\n",
    "}\n",
    "\n",
    "agent_params = {\n",
    "    \"tensorboard_log\":f\"{EnvConfig.TENSORBOARD_LOG_PATH_PREFIX}{EnvConfig.configurations[EnvConfig.CURRENT_CONFIGURATION_INDEX]['name']}\",\n",
    "    \"verbose\":1,\n",
    "    \"n_epochs\":3,\n",
    "    \"n_steps\": 4096,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 64,\n",
    "    \"seed\": 0,\n",
    "    'policy_kwargs': {'features_extractor_class': CustomCNN}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/logs_for_deathmatch\\PPO_43\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 25      |\n",
      "|    iterations      | 1       |\n",
      "|    time_elapsed    | 319     |\n",
      "|    total_timesteps | 5308192 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 23          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 700         |\n",
      "|    total_timesteps      | 5316384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.052063845 |\n",
      "|    clip_fraction        | 0.54        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | -0.115      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 1941        |\n",
      "|    policy_gradient_loss | 0.0255      |\n",
      "|    value_loss           | 0.594       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 1076        |\n",
      "|    total_timesteps      | 5324576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020030934 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.0797      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 1944        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.532       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 22          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 1452        |\n",
      "|    total_timesteps      | 5332768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020781152 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 1947        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.698       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 22         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 1833       |\n",
      "|    total_timesteps      | 5340960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02345433 |\n",
      "|    clip_fraction        | 0.254      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.179      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0583     |\n",
      "|    n_updates            | 1950       |\n",
      "|    policy_gradient_loss | -0.0181    |\n",
      "|    value_loss           | 0.483      |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 22       |\n",
      "|    iterations           | 6        |\n",
      "|    time_elapsed         | 2213     |\n",
      "|    total_timesteps      | 5349152  |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.021793 |\n",
      "|    clip_fraction        | 0.274    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.16    |\n",
      "|    explained_variance   | 0.221    |\n",
      "|    learning_rate        | 0.0001   |\n",
      "|    loss                 | 0.156    |\n",
      "|    n_updates            | 1953     |\n",
      "|    policy_gradient_loss | -0.0163  |\n",
      "|    value_loss           | 0.577    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Programs\\Anaconda\\envs\\py37\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:71: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=5350000, episode_reward=4.40 +/- 3.23\n",
      "Episode length: 99.10 +/- 16.83\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 99.1        |\n",
      "|    mean_reward          | 4.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025176445 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.215       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.0669      |\n",
      "|    n_updates            | 1956        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.61        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 21      |\n",
      "|    iterations      | 7       |\n",
      "|    time_elapsed    | 2649    |\n",
      "|    total_timesteps | 5357344 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 3032        |\n",
      "|    total_timesteps      | 5365536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025429495 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.477       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.19        |\n",
      "|    n_updates            | 1959        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 3420        |\n",
      "|    total_timesteps      | 5373728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026680473 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.601       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.195       |\n",
      "|    n_updates            | 1962        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.948       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 10         |\n",
      "|    time_elapsed         | 3800       |\n",
      "|    total_timesteps      | 5381920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03182146 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.237      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.23       |\n",
      "|    n_updates            | 1965       |\n",
      "|    policy_gradient_loss | -0.0184    |\n",
      "|    value_loss           | 0.651      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 4175        |\n",
      "|    total_timesteps      | 5390112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027461244 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.352       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 1968        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.783       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 4560        |\n",
      "|    total_timesteps      | 5398304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027837018 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.446       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 1971        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.753       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5400000, episode_reward=4.80 +/- 4.64\n",
      "Episode length: 101.50 +/- 24.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 102         |\n",
      "|    mean_reward          | 4.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5400000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026024964 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.147       |\n",
      "|    n_updates            | 1974        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.727       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 21      |\n",
      "|    iterations      | 13      |\n",
      "|    time_elapsed    | 5014    |\n",
      "|    total_timesteps | 5406496 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 5394        |\n",
      "|    total_timesteps      | 5414688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028248627 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.403       |\n",
      "|    n_updates            | 1977        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.749       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 5772        |\n",
      "|    total_timesteps      | 5422880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026416283 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.239       |\n",
      "|    n_updates            | 1980        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.762       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 6152        |\n",
      "|    total_timesteps      | 5431072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024849499 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.114       |\n",
      "|    n_updates            | 1983        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.864       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 6523       |\n",
      "|    total_timesteps      | 5439264    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02333825 |\n",
      "|    clip_fraction        | 0.248      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0.418      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.0997     |\n",
      "|    n_updates            | 1986       |\n",
      "|    policy_gradient_loss | -0.015     |\n",
      "|    value_loss           | 0.7        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 6895       |\n",
      "|    total_timesteps      | 5447456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02437574 |\n",
      "|    clip_fraction        | 0.241      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.343      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.338      |\n",
      "|    n_updates            | 1989       |\n",
      "|    policy_gradient_loss | -0.0161    |\n",
      "|    value_loss           | 0.789      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=5450000, episode_reward=4.00 +/- 3.32\n",
      "Episode length: 103.30 +/- 25.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 103         |\n",
      "|    mean_reward          | 4           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025135476 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.212       |\n",
      "|    n_updates            | 1992        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 0.857       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 21      |\n",
      "|    iterations      | 19      |\n",
      "|    time_elapsed    | 7350    |\n",
      "|    total_timesteps | 5455648 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 7735        |\n",
      "|    total_timesteps      | 5463840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024331093 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.227       |\n",
      "|    n_updates            | 1995        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.899       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 8110        |\n",
      "|    total_timesteps      | 5472032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025261614 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.395       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.165       |\n",
      "|    n_updates            | 1998        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.8         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 8500        |\n",
      "|    total_timesteps      | 5480224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026977267 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.516       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.288       |\n",
      "|    n_updates            | 2001        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.843       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 8884        |\n",
      "|    total_timesteps      | 5488416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028210849 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.284       |\n",
      "|    n_updates            | 2004        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 9269        |\n",
      "|    total_timesteps      | 5496608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026953835 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.136       |\n",
      "|    n_updates            | 2007        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.869       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5500000, episode_reward=5.40 +/- 2.37\n",
      "Episode length: 127.40 +/- 31.62\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 127         |\n",
      "|    mean_reward          | 5.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027631793 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.455       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.151       |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.92        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 21      |\n",
      "|    iterations      | 25      |\n",
      "|    time_elapsed    | 9720    |\n",
      "|    total_timesteps | 5504800 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 10099       |\n",
      "|    total_timesteps      | 5512992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027006462 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.146       |\n",
      "|    n_updates            | 2013        |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 10483       |\n",
      "|    total_timesteps      | 5521184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026630323 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.428       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.157       |\n",
      "|    n_updates            | 2016        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.953       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 10872       |\n",
      "|    total_timesteps      | 5529376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027245505 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.452       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.123       |\n",
      "|    n_updates            | 2019        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 11251       |\n",
      "|    total_timesteps      | 5537568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026646253 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.253       |\n",
      "|    n_updates            | 2022        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 11633       |\n",
      "|    total_timesteps      | 5545760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030512594 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.282       |\n",
      "|    n_updates            | 2025        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 1.35        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5550000, episode_reward=9.90 +/- 10.89\n",
      "Episode length: 181.50 +/- 104.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 182         |\n",
      "|    mean_reward          | 9.9         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024074841 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.331       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.237       |\n",
      "|    n_updates            | 2028        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 31      |\n",
      "|    time_elapsed    | 12099   |\n",
      "|    total_timesteps | 5553952 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 12478       |\n",
      "|    total_timesteps      | 5562144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032044645 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.16        |\n",
      "|    n_updates            | 2031        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 12860       |\n",
      "|    total_timesteps      | 5570336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024182405 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.358       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.443       |\n",
      "|    n_updates            | 2034        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 13244       |\n",
      "|    total_timesteps      | 5578528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025632612 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.435       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.219       |\n",
      "|    n_updates            | 2037        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 35         |\n",
      "|    time_elapsed         | 13621      |\n",
      "|    total_timesteps      | 5586720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02843424 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0.339      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.241      |\n",
      "|    n_updates            | 2040       |\n",
      "|    policy_gradient_loss | -0.0159    |\n",
      "|    value_loss           | 1.07       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 14007       |\n",
      "|    total_timesteps      | 5594912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029786197 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.215       |\n",
      "|    n_updates            | 2043        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5600000, episode_reward=4.90 +/- 2.39\n",
      "Episode length: 131.30 +/- 41.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 131         |\n",
      "|    mean_reward          | 4.9         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026102532 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.43        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.304       |\n",
      "|    n_updates            | 2046        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 37      |\n",
      "|    time_elapsed    | 14452   |\n",
      "|    total_timesteps | 5603104 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 20        |\n",
      "|    iterations           | 38        |\n",
      "|    time_elapsed         | 14829     |\n",
      "|    total_timesteps      | 5611296   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0240783 |\n",
      "|    clip_fraction        | 0.251     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.02     |\n",
      "|    explained_variance   | 0.381     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.272     |\n",
      "|    n_updates            | 2049      |\n",
      "|    policy_gradient_loss | -0.0108   |\n",
      "|    value_loss           | 0.977     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 15215       |\n",
      "|    total_timesteps      | 5619488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025940936 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.96       |\n",
      "|    explained_variance   | 0.416       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.279       |\n",
      "|    n_updates            | 2052        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 15593       |\n",
      "|    total_timesteps      | 5627680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022903975 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.989      |\n",
      "|    explained_variance   | 0.42        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.226       |\n",
      "|    n_updates            | 2055        |\n",
      "|    policy_gradient_loss | -0.00939    |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 21          |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 15982       |\n",
      "|    total_timesteps      | 5635872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024123333 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.995      |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.527       |\n",
      "|    n_updates            | 2058        |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 21         |\n",
      "|    iterations           | 42         |\n",
      "|    time_elapsed         | 16365      |\n",
      "|    total_timesteps      | 5644064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02757978 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.02      |\n",
      "|    explained_variance   | 0.291      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.147      |\n",
      "|    n_updates            | 2061       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    value_loss           | 0.82       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=5650000, episode_reward=3.50 +/- 3.69\n",
      "Episode length: 139.90 +/- 55.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 140         |\n",
      "|    mean_reward          | 3.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5650000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023605186 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.182       |\n",
      "|    n_updates            | 2064        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 43      |\n",
      "|    time_elapsed    | 16814   |\n",
      "|    total_timesteps | 5652256 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 44          |\n",
      "|    time_elapsed         | 17200       |\n",
      "|    total_timesteps      | 5660448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024556827 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.981      |\n",
      "|    explained_variance   | 0.429       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.267       |\n",
      "|    n_updates            | 2067        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 1.08        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 45          |\n",
      "|    time_elapsed         | 17584       |\n",
      "|    total_timesteps      | 5668640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024132535 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.977      |\n",
      "|    explained_variance   | 0.314       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.262       |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.00834    |\n",
      "|    value_loss           | 1.28        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 17963       |\n",
      "|    total_timesteps      | 5676832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025173271 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.338       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.306       |\n",
      "|    n_updates            | 2073        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 47         |\n",
      "|    time_elapsed         | 18344      |\n",
      "|    total_timesteps      | 5685024    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02673429 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.948     |\n",
      "|    explained_variance   | 0.375      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.301      |\n",
      "|    n_updates            | 2076       |\n",
      "|    policy_gradient_loss | -0.00929   |\n",
      "|    value_loss           | 1.33       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 18726       |\n",
      "|    total_timesteps      | 5693216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024377681 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.951      |\n",
      "|    explained_variance   | 0.443       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.24        |\n",
      "|    n_updates            | 2079        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 1.04        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5700000, episode_reward=7.90 +/- 10.32\n",
      "Episode length: 210.80 +/- 98.33\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 211         |\n",
      "|    mean_reward          | 7.9         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023975901 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.501       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 2082        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 1.31        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 49      |\n",
      "|    time_elapsed    | 19208   |\n",
      "|    total_timesteps | 5701408 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 19589       |\n",
      "|    total_timesteps      | 5709600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025907785 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.488       |\n",
      "|    n_updates            | 2085        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 1.46        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 19974       |\n",
      "|    total_timesteps      | 5717792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025221895 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.404       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.535       |\n",
      "|    n_updates            | 2088        |\n",
      "|    policy_gradient_loss | -0.00961    |\n",
      "|    value_loss           | 1.63        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 20354       |\n",
      "|    total_timesteps      | 5725984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026835434 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.917      |\n",
      "|    explained_variance   | 0.413       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.236       |\n",
      "|    n_updates            | 2091        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 20731       |\n",
      "|    total_timesteps      | 5734176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031716764 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.904      |\n",
      "|    explained_variance   | 0.318       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.4         |\n",
      "|    n_updates            | 2094        |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 1.43        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 54          |\n",
      "|    time_elapsed         | 21111       |\n",
      "|    total_timesteps      | 5742368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028608892 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.925      |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.3         |\n",
      "|    n_updates            | 2097        |\n",
      "|    policy_gradient_loss | -0.00679    |\n",
      "|    value_loss           | 1.47        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5750000, episode_reward=14.20 +/- 9.74\n",
      "Episode length: 286.00 +/- 118.21\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 286         |\n",
      "|    mean_reward          | 14.2        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5750000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030008053 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.346       |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 55      |\n",
      "|    time_elapsed    | 21618   |\n",
      "|    total_timesteps | 5750560 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 22003       |\n",
      "|    total_timesteps      | 5758752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030677252 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.969      |\n",
      "|    explained_variance   | 0.341       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.299       |\n",
      "|    n_updates            | 2103        |\n",
      "|    policy_gradient_loss | -0.00885    |\n",
      "|    value_loss           | 1.18        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 22382       |\n",
      "|    total_timesteps      | 5766944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029677484 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.937      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.168       |\n",
      "|    n_updates            | 2106        |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    value_loss           | 1.06        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 22763       |\n",
      "|    total_timesteps      | 5775136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032640997 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.952      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.106       |\n",
      "|    n_updates            | 2109        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 1.09        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 59          |\n",
      "|    time_elapsed         | 23147       |\n",
      "|    total_timesteps      | 5783328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027530998 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.915      |\n",
      "|    explained_variance   | 0.317       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.396       |\n",
      "|    n_updates            | 2112        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 1.34        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 23532       |\n",
      "|    total_timesteps      | 5791520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026916284 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.93       |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.431       |\n",
      "|    n_updates            | 2115        |\n",
      "|    policy_gradient_loss | -0.00908    |\n",
      "|    value_loss           | 1.58        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 61          |\n",
      "|    time_elapsed         | 23920       |\n",
      "|    total_timesteps      | 5799712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026541606 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.94       |\n",
      "|    explained_variance   | 0.453       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.326       |\n",
      "|    n_updates            | 2118        |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    value_loss           | 1.73        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5800000, episode_reward=7.60 +/- 7.50\n",
      "Episode length: 185.60 +/- 72.24\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 186         |\n",
      "|    mean_reward          | 7.6         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5800000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026033852 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.956      |\n",
      "|    explained_variance   | 0.357       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.382       |\n",
      "|    n_updates            | 2121        |\n",
      "|    policy_gradient_loss | -0.00835    |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 62      |\n",
      "|    time_elapsed    | 24388   |\n",
      "|    total_timesteps | 5807904 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 63         |\n",
      "|    time_elapsed         | 24771      |\n",
      "|    total_timesteps      | 5816096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03320364 |\n",
      "|    clip_fraction        | 0.269      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.948     |\n",
      "|    explained_variance   | 0.445      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.267      |\n",
      "|    n_updates            | 2124       |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    value_loss           | 1.31       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 64          |\n",
      "|    time_elapsed         | 25154       |\n",
      "|    total_timesteps      | 5824288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029898157 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.97       |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.3         |\n",
      "|    n_updates            | 2127        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 65         |\n",
      "|    time_elapsed         | 25535      |\n",
      "|    total_timesteps      | 5832480    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03246846 |\n",
      "|    clip_fraction        | 0.292      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.976     |\n",
      "|    explained_variance   | 0.372      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.243      |\n",
      "|    n_updates            | 2130       |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    value_loss           | 0.895      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 25914       |\n",
      "|    total_timesteps      | 5840672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027358415 |\n",
      "|    clip_fraction        | 0.266       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.366       |\n",
      "|    n_updates            | 2133        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.947       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 26303       |\n",
      "|    total_timesteps      | 5848864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028460031 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.912      |\n",
      "|    explained_variance   | 0.401       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.153       |\n",
      "|    n_updates            | 2136        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 0.946       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5850000, episode_reward=5.50 +/- 3.75\n",
      "Episode length: 200.50 +/- 52.74\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 200         |\n",
      "|    mean_reward          | 5.5         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028244281 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.909      |\n",
      "|    explained_variance   | 0.316       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.241       |\n",
      "|    n_updates            | 2139        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.867       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 68      |\n",
      "|    time_elapsed    | 26772   |\n",
      "|    total_timesteps | 5857056 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 69          |\n",
      "|    time_elapsed         | 27154       |\n",
      "|    total_timesteps      | 5865248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028871106 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.919      |\n",
      "|    explained_variance   | 0.199       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.297       |\n",
      "|    n_updates            | 2142        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 1.3         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 70          |\n",
      "|    time_elapsed         | 27536       |\n",
      "|    total_timesteps      | 5873440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029200297 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | 0.276       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.321       |\n",
      "|    n_updates            | 2145        |\n",
      "|    policy_gradient_loss | -0.00843    |\n",
      "|    value_loss           | 1.21        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 71         |\n",
      "|    time_elapsed         | 27918      |\n",
      "|    total_timesteps      | 5881632    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03177447 |\n",
      "|    clip_fraction        | 0.266      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.91      |\n",
      "|    explained_variance   | 0.359      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.472      |\n",
      "|    n_updates            | 2148       |\n",
      "|    policy_gradient_loss | -0.00894   |\n",
      "|    value_loss           | 1.3        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 28307       |\n",
      "|    total_timesteps      | 5889824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027975183 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.258       |\n",
      "|    n_updates            | 2151        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.964       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 28690       |\n",
      "|    total_timesteps      | 5898016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030007862 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.839      |\n",
      "|    explained_variance   | 0.449       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.315       |\n",
      "|    n_updates            | 2154        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5900000, episode_reward=7.20 +/- 3.31\n",
      "Episode length: 261.70 +/- 121.85\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 262         |\n",
      "|    mean_reward          | 7.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030703463 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.763      |\n",
      "|    explained_variance   | 0.288       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.359       |\n",
      "|    n_updates            | 2157        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 74      |\n",
      "|    time_elapsed    | 29187   |\n",
      "|    total_timesteps | 5906208 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 29564       |\n",
      "|    total_timesteps      | 5914400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027027348 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.78       |\n",
      "|    explained_variance   | 0.339       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.298       |\n",
      "|    n_updates            | 2160        |\n",
      "|    policy_gradient_loss | -0.00952    |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 29948       |\n",
      "|    total_timesteps      | 5922592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029677745 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.824      |\n",
      "|    explained_variance   | 0.466       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.249       |\n",
      "|    n_updates            | 2163        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 30333       |\n",
      "|    total_timesteps      | 5930784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030017754 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.849      |\n",
      "|    explained_variance   | 0.431       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.213       |\n",
      "|    n_updates            | 2166        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.944       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 30718       |\n",
      "|    total_timesteps      | 5938976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030650629 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | 0.436       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.323       |\n",
      "|    n_updates            | 2169        |\n",
      "|    policy_gradient_loss | -0.00942    |\n",
      "|    value_loss           | 1.22        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 79          |\n",
      "|    time_elapsed         | 31102       |\n",
      "|    total_timesteps      | 5947168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031900067 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.898      |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.314       |\n",
      "|    n_updates            | 2172        |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.973       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=5950000, episode_reward=18.00 +/- 10.52\n",
      "Episode length: 299.60 +/- 70.42\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 300         |\n",
      "|    mean_reward          | 18          |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 5950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029558912 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.903      |\n",
      "|    explained_variance   | 0.366       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.207       |\n",
      "|    n_updates            | 2175        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 1.11        |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 80      |\n",
      "|    time_elapsed    | 31622   |\n",
      "|    total_timesteps | 5955360 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 32002       |\n",
      "|    total_timesteps      | 5963552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033177212 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.362       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.193       |\n",
      "|    n_updates            | 2178        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.961       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 32391       |\n",
      "|    total_timesteps      | 5971744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032596834 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.407       |\n",
      "|    n_updates            | 2181        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 1.01        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 32777       |\n",
      "|    total_timesteps      | 5979936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031291477 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.833      |\n",
      "|    explained_variance   | 0.33        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.25        |\n",
      "|    n_updates            | 2184        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 84          |\n",
      "|    time_elapsed         | 33164       |\n",
      "|    total_timesteps      | 5988128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038194664 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.184       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.595       |\n",
      "|    n_updates            | 2187        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    value_loss           | 1.02        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 85          |\n",
      "|    time_elapsed         | 33546       |\n",
      "|    total_timesteps      | 5996320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027866663 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.0631      |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.312       |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.00722    |\n",
      "|    value_loss           | 1.26        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6000000, episode_reward=8.10 +/- 4.81\n",
      "Episode length: 439.10 +/- 199.61\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 439         |\n",
      "|    mean_reward          | 8.1         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027387675 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.521       |\n",
      "|    n_updates            | 2193        |\n",
      "|    policy_gradient_loss | -0.0079     |\n",
      "|    value_loss           | 1.13        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 86      |\n",
      "|    time_elapsed    | 34119   |\n",
      "|    total_timesteps | 6004512 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 87          |\n",
      "|    time_elapsed         | 34498       |\n",
      "|    total_timesteps      | 6012704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026771147 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.828      |\n",
      "|    explained_variance   | 0.438       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.34        |\n",
      "|    n_updates            | 2196        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 1.07        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 88          |\n",
      "|    time_elapsed         | 34874       |\n",
      "|    total_timesteps      | 6020896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027225617 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.778      |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.357       |\n",
      "|    n_updates            | 2199        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    value_loss           | 1.24        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 35259       |\n",
      "|    total_timesteps      | 6029088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027911246 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.777      |\n",
      "|    explained_variance   | 0.399       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.231       |\n",
      "|    n_updates            | 2202        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.946       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 90          |\n",
      "|    time_elapsed         | 35640       |\n",
      "|    total_timesteps      | 6037280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025053564 |\n",
      "|    clip_fraction        | 0.233       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.809      |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.288       |\n",
      "|    n_updates            | 2205        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    value_loss           | 1.15        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 36022       |\n",
      "|    total_timesteps      | 6045472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028468907 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.747      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.322       |\n",
      "|    n_updates            | 2208        |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6050000, episode_reward=17.60 +/- 8.95\n",
      "Episode length: 532.00 +/- 169.72\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 532         |\n",
      "|    mean_reward          | 17.6        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027790736 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.752      |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.338       |\n",
      "|    n_updates            | 2211        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.993       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 92      |\n",
      "|    time_elapsed    | 36632   |\n",
      "|    total_timesteps | 6053664 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 93         |\n",
      "|    time_elapsed         | 37020      |\n",
      "|    total_timesteps      | 6061856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02590185 |\n",
      "|    clip_fraction        | 0.219      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.732     |\n",
      "|    explained_variance   | 0.392      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.494      |\n",
      "|    n_updates            | 2214       |\n",
      "|    policy_gradient_loss | -0.00833   |\n",
      "|    value_loss           | 1.05       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 37402       |\n",
      "|    total_timesteps      | 6070048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031142795 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.714      |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.206       |\n",
      "|    n_updates            | 2217        |\n",
      "|    policy_gradient_loss | -0.00701    |\n",
      "|    value_loss           | 1.16        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 95         |\n",
      "|    time_elapsed         | 37778      |\n",
      "|    total_timesteps      | 6078240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03235112 |\n",
      "|    clip_fraction        | 0.232      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.727     |\n",
      "|    explained_variance   | 0.268      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.218      |\n",
      "|    n_updates            | 2220       |\n",
      "|    policy_gradient_loss | -0.0084    |\n",
      "|    value_loss           | 1.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 38163       |\n",
      "|    total_timesteps      | 6086432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038006954 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.77       |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.541       |\n",
      "|    n_updates            | 2223        |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    value_loss           | 1.19        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 97         |\n",
      "|    time_elapsed         | 38546      |\n",
      "|    total_timesteps      | 6094624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03130092 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.727     |\n",
      "|    explained_variance   | 0.345      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.336      |\n",
      "|    n_updates            | 2226       |\n",
      "|    policy_gradient_loss | -0.00826   |\n",
      "|    value_loss           | 1.07       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=6100000, episode_reward=6.80 +/- 8.74\n",
      "Episode length: 311.50 +/- 186.84\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 312         |\n",
      "|    mean_reward          | 6.8         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032440744 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.713      |\n",
      "|    explained_variance   | 0.386       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.133       |\n",
      "|    n_updates            | 2229        |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.847       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 98      |\n",
      "|    time_elapsed    | 39059   |\n",
      "|    total_timesteps | 6102816 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 20        |\n",
      "|    iterations           | 99        |\n",
      "|    time_elapsed         | 39445     |\n",
      "|    total_timesteps      | 6111008   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0318933 |\n",
      "|    clip_fraction        | 0.244     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.733    |\n",
      "|    explained_variance   | 0.413     |\n",
      "|    learning_rate        | 0.0001    |\n",
      "|    loss                 | 0.297     |\n",
      "|    n_updates            | 2232      |\n",
      "|    policy_gradient_loss | -0.00621  |\n",
      "|    value_loss           | 1.09      |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 39832       |\n",
      "|    total_timesteps      | 6119200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033656046 |\n",
      "|    clip_fraction        | 0.25        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.721      |\n",
      "|    explained_variance   | 0.355       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.222       |\n",
      "|    n_updates            | 2235        |\n",
      "|    policy_gradient_loss | -0.00848    |\n",
      "|    value_loss           | 0.91        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 40217       |\n",
      "|    total_timesteps      | 6127392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028129343 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.271       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.481       |\n",
      "|    n_updates            | 2238        |\n",
      "|    policy_gradient_loss | -0.00601    |\n",
      "|    value_loss           | 1.23        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 40600       |\n",
      "|    total_timesteps      | 6135584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029786967 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.695      |\n",
      "|    explained_variance   | 0.444       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 2241        |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    value_loss           | 0.896       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 103        |\n",
      "|    time_elapsed         | 40979      |\n",
      "|    total_timesteps      | 6143776    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03396699 |\n",
      "|    clip_fraction        | 0.238      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.692     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.333      |\n",
      "|    n_updates            | 2244       |\n",
      "|    policy_gradient_loss | -0.00679   |\n",
      "|    value_loss           | 1.09       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=6150000, episode_reward=2.20 +/- 4.75\n",
      "Episode length: 355.10 +/- 140.86\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 355         |\n",
      "|    mean_reward          | 2.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036437728 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.738      |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.285       |\n",
      "|    n_updates            | 2247        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 104     |\n",
      "|    time_elapsed    | 41515   |\n",
      "|    total_timesteps | 6151968 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 41893       |\n",
      "|    total_timesteps      | 6160160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028632145 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | 0.258       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.242       |\n",
      "|    n_updates            | 2250        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.983       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 106        |\n",
      "|    time_elapsed         | 42272      |\n",
      "|    total_timesteps      | 6168352    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03465289 |\n",
      "|    clip_fraction        | 0.239      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.729     |\n",
      "|    explained_variance   | 0.416      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.358      |\n",
      "|    n_updates            | 2253       |\n",
      "|    policy_gradient_loss | -0.0126    |\n",
      "|    value_loss           | 0.778      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 42652       |\n",
      "|    total_timesteps      | 6176544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037584685 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.74       |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.337       |\n",
      "|    n_updates            | 2256        |\n",
      "|    policy_gradient_loss | -0.00724    |\n",
      "|    value_loss           | 1.5         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 108         |\n",
      "|    time_elapsed         | 43040       |\n",
      "|    total_timesteps      | 6184736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037641607 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.763      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.558       |\n",
      "|    n_updates            | 2259        |\n",
      "|    policy_gradient_loss | -0.00196    |\n",
      "|    value_loss           | 1.29        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 43426       |\n",
      "|    total_timesteps      | 6192928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040089175 |\n",
      "|    clip_fraction        | 0.286       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.457       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.22        |\n",
      "|    n_updates            | 2262        |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    value_loss           | 1.25        |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6200000, episode_reward=8.40 +/- 5.28\n",
      "Episode length: 191.00 +/- 69.35\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 191         |\n",
      "|    mean_reward          | 8.4         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6200000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038630366 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.78       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.261       |\n",
      "|    n_updates            | 2265        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 0.978       |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 110     |\n",
      "|    time_elapsed    | 43892   |\n",
      "|    total_timesteps | 6201120 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 111        |\n",
      "|    time_elapsed         | 44279      |\n",
      "|    total_timesteps      | 6209312    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03908006 |\n",
      "|    clip_fraction        | 0.295      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.792     |\n",
      "|    explained_variance   | 0.449      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.208      |\n",
      "|    n_updates            | 2268       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 0.813      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 112        |\n",
      "|    time_elapsed         | 44662      |\n",
      "|    total_timesteps      | 6217504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03635385 |\n",
      "|    clip_fraction        | 0.27       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.78      |\n",
      "|    explained_variance   | 0.404      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.323      |\n",
      "|    n_updates            | 2271       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    value_loss           | 0.996      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 113        |\n",
      "|    time_elapsed         | 45047      |\n",
      "|    total_timesteps      | 6225696    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03444369 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.816     |\n",
      "|    explained_variance   | 0.522      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.385      |\n",
      "|    n_updates            | 2274       |\n",
      "|    policy_gradient_loss | -0.00862   |\n",
      "|    value_loss           | 1.15       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 45426       |\n",
      "|    total_timesteps      | 6233888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037691295 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.795      |\n",
      "|    explained_variance   | 0.447       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.286       |\n",
      "|    n_updates            | 2277        |\n",
      "|    policy_gradient_loss | -0.00953    |\n",
      "|    value_loss           | 1.03        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 115        |\n",
      "|    time_elapsed         | 45807      |\n",
      "|    total_timesteps      | 6242080    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03279113 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.861     |\n",
      "|    explained_variance   | 0.332      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.115      |\n",
      "|    n_updates            | 2280       |\n",
      "|    policy_gradient_loss | -0.0103    |\n",
      "|    value_loss           | 1.01       |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=6250000, episode_reward=6.60 +/- 5.39\n",
      "Episode length: 398.50 +/- 175.46\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 398        |\n",
      "|    mean_reward          | 6.6        |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 6250000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03321676 |\n",
      "|    clip_fraction        | 0.279      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.838     |\n",
      "|    explained_variance   | 0.4        |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.355      |\n",
      "|    n_updates            | 2283       |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    value_loss           | 1.15       |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 20      |\n",
      "|    iterations      | 116     |\n",
      "|    time_elapsed    | 46367   |\n",
      "|    total_timesteps | 6250272 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 46752       |\n",
      "|    total_timesteps      | 6258464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033513475 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | 0.333       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.272       |\n",
      "|    n_updates            | 2286        |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    value_loss           | 1.2         |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 118         |\n",
      "|    time_elapsed         | 47134       |\n",
      "|    total_timesteps      | 6266656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036847554 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.867      |\n",
      "|    explained_variance   | 0.414       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.228       |\n",
      "|    n_updates            | 2289        |\n",
      "|    policy_gradient_loss | -0.0076     |\n",
      "|    value_loss           | 0.991       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 47518       |\n",
      "|    total_timesteps      | 6274848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036931366 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.865      |\n",
      "|    explained_variance   | 0.373       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.254       |\n",
      "|    n_updates            | 2292        |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    value_loss           | 0.893       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 47897       |\n",
      "|    total_timesteps      | 6283040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033680774 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.342       |\n",
      "|    n_updates            | 2295        |\n",
      "|    policy_gradient_loss | -0.00687    |\n",
      "|    value_loss           | 1.17        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 20         |\n",
      "|    iterations           | 121        |\n",
      "|    time_elapsed         | 48280      |\n",
      "|    total_timesteps      | 6291232    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03202212 |\n",
      "|    clip_fraction        | 0.263      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.828     |\n",
      "|    explained_variance   | 0.316      |\n",
      "|    learning_rate        | 0.0001     |\n",
      "|    loss                 | 0.21       |\n",
      "|    n_updates            | 2298       |\n",
      "|    policy_gradient_loss | -0.00876   |\n",
      "|    value_loss           | 1.07       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 20          |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 48664       |\n",
      "|    total_timesteps      | 6299424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035689246 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | 0.34        |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.239       |\n",
      "|    n_updates            | 2301        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 0.808       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=6300000, episode_reward=11.70 +/- 7.25\n",
      "Episode length: 272.00 +/- 61.30\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 272         |\n",
      "|    mean_reward          | 11.7        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 6300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033429712 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0.323       |\n",
      "|    learning_rate        | 0.0001      |\n",
      "|    loss                 | 0.176       |\n",
      "|    n_updates            | 2304        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 1.05        |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# RUN THE ENVIRONMENT IN PARALLEL MODE WITH 2 ENVS\n",
    "\n",
    "from EnvironmentHelpers import create_vectorised_environment\n",
    "from stable_baselines3.common.callbacks import EvalCallback\n",
    "\n",
    "from utils.initialisation import initialise_network_weights\n",
    "\n",
    "env = create_vectorised_environment(**env_params, n_envs=2)\n",
    "\n",
    "evaluation_env = create_vectorised_environment(**evaluation_env_params, n_envs=1)\n",
    "\n",
    "evaluation_callback = EvalCallback(\n",
    "            evaluation_env, \n",
    "            n_eval_episodes=10, \n",
    "            eval_freq=evaluation_freq,\n",
    "            log_path=f\"{EnvConfig.TENSORBOARD_LOG_PATH_PREFIX}{EnvConfig.configurations[EnvConfig.CURRENT_CONFIGURATION_INDEX]['name']}\",\n",
    "            best_model_save_path=f'models/{EnvConfig.configurations[EnvConfig.CURRENT_CONFIGURATION_INDEX][\"name\"]}')\n",
    "\n",
    "model = PPO(policies.ActorCriticCnnPolicy, env, device=\"cuda\", **agent_params)\n",
    "# model = PPO.load(f\"{EnvConfig.AGENT_MODEL_PATH_PREFIX}{EnvConfig.configurations[EnvConfig.CURRENT_CONFIGURATION_INDEX]['name']}/model_2650000\", **agent_params)\n",
    "# model.set_env(env)\n",
    "\n",
    "register_hooks(model)\n",
    "initialise_network_weights(model.policy)\n",
    "\n",
    "# model.learn(total_timesteps=30000000, callback=[agentCallback, evaluation_callback], reset_num_timesteps=False)\n",
    "\n",
    "\n",
    "model.learn(total_timesteps=30000000, callback=[agentCallback, evaluation_callback])\n",
    "# model.learn(total_timesteps=3000000, callback=[agentCallback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()\n",
    "evaluation_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE ACTIVATIONS\n",
    "from utils.initialisation import initialise_network_weights\n",
    "\n",
    "env = create_vectorised_environment(**env_params, n_envs=2)\n",
    "# evaluation_env = create_vectorised_environment(**env_params, n_envs=1)\n",
    "\n",
    "\n",
    "model = PPO(policies.ActorCriticCnnPolicy, env, **agent_params)\n",
    "\n",
    "register_hooks(model)\n",
    "initialise_network_weights(model.policy)\n",
    "\n",
    "model.learn(total_timesteps=1024, callback=[LayerActivationMonitoring()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_activations(model.policy.features_extractor.hooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = PPO.load(f\"{EnvConfig.AGENT_MODEL_PATH_PREFIX}{EnvConfig.configurations[EnvConfig.CURRENT_CONFIGURATION_INDEX]['name']}/model_125000\")\n",
    "model.set_env(env)\n",
    "model.learn(total_timesteps=3000000, callback=agentCallback, reset_num_timesteps=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6cba2736cce089a2bdaa6e7154cabef02622ca008eb343f0722e476d9fdc3920"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
